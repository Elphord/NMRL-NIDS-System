{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, jsonify, request\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "import warnings\n",
    "import os\n",
    "import absl.logging\n",
    "from scapy.all import sniff, Ether, IP, TCP, UDP, ICMP\n",
    "from collections import defaultdict\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "# Suppress TensorFlow warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Ensure models directory exists\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Load models at startup\n",
    "models = {\n",
    "    'scaler': None,\n",
    "    'autoencoder': None,\n",
    "    'autoencoder_threshold': None,\n",
    "    'kmeans': None,\n",
    "    'kmeans_threshold': None,\n",
    "    'isolation_forest': None,\n",
    "    'feature_cols': None\n",
    "}\n",
    "\n",
    "def load_models():\n",
    "    \"\"\"Load all the trained models\"\"\"\n",
    "    try:\n",
    "        print(\"Loading models...\")\n",
    "        models['scaler'] = joblib.load('models/scaler.pkl')\n",
    "        models['autoencoder'] = load_model('models/autoencoder_model.h5')\n",
    "        models['kmeans'] = joblib.load('models/kmeans_model.pkl')\n",
    "        models['isolation_forest'] = joblib.load('models/isolation_forest_model.pkl')\n",
    "        \n",
    "        with open('models/autoencoder_threshold.pkl', 'rb') as f:\n",
    "            models['autoencoder_threshold'] = pickle.load(f)\n",
    "            \n",
    "        with open('models/kmeans_threshold.pkl', 'rb') as f:\n",
    "            models['kmeans_threshold'] = pickle.load(f)\n",
    "            \n",
    "        # These should match the features used during training\n",
    "        models['feature_cols'] = [\n",
    "            'packet_size', 'protocol', 'src_port', 'dst_port',\n",
    "            'tcp_fin', 'tcp_syn', 'tcp_rst', 'tcp_psh', 'tcp_ack', 'tcp_urg'\n",
    "        ]\n",
    "        \n",
    "        print(\"All models loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models: {str(e)}\")\n",
    "        # Create dummy models for demonstration if real models fail to load\n",
    "        models['feature_cols'] = [\n",
    "            'packet_size', 'protocol', 'src_port', 'dst_port',\n",
    "            'tcp_fin', 'tcp_syn', 'tcp_rst', 'tcp_psh', 'tcp_ack', 'tcp_urg'\n",
    "        ]\n",
    "\n",
    "# Load models when app starts\n",
    "load_models()\n",
    "\n",
    "# Data storage for real packet capture\n",
    "traffic_data = {\n",
    "    'timestamps': [],\n",
    "    'packet_counts': [],\n",
    "    'protocol_distribution': {\n",
    "        'TCP': 0,\n",
    "        'UDP': 0,\n",
    "        'ICMP': 0,\n",
    "        'HTTP': 0,\n",
    "        'HTTPS': 0,\n",
    "        'Other': 0\n",
    "    },\n",
    "    'anomalies': [],\n",
    "    'alerts': [],\n",
    "    'packet_buffer': [],\n",
    "    'stats': {\n",
    "        'total_packets': 0,\n",
    "        'start_time': datetime.now()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Packet processing function\n",
    "def process_packet(packet):\n",
    "    \"\"\"Process each captured packet and extract features\"\"\"\n",
    "    try:\n",
    "        # Basic packet information\n",
    "        packet_info = {\n",
    "            'timestamp': datetime.now().strftime('%H:%M:%S'),\n",
    "            'size': len(packet),\n",
    "            'protocol': 'Other',\n",
    "            'src_port': None,\n",
    "            'dst_port': None,\n",
    "            'tcp_flags': {\n",
    "                'fin': 0, 'syn': 0, 'rst': 0, \n",
    "                'psh': 0, 'ack': 0, 'urg': 0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Update protocol distribution\n",
    "        if packet.haslayer(IP):\n",
    "            if packet.haslayer(TCP):\n",
    "                packet_info['protocol'] = 'HTTPS' if packet[TCP].dport == 443 or packet[TCP].sport == 443 else 'HTTP' if packet[TCP].dport == 80 or packet[TCP].sport == 80 else 'TCP'\n",
    "                packet_info['src_port'] = packet[TCP].sport\n",
    "                packet_info['dst_port'] = packet[TCP].dport\n",
    "                packet_info['tcp_flags']['fin'] = packet[TCP].flags.F\n",
    "                packet_info['tcp_flags']['syn'] = packet[TCP].flags.S\n",
    "                packet_info['tcp_flags']['rst'] = packet[TCP].flags.R\n",
    "                packet_info['tcp_flags']['psh'] = packet[TCP].flags.P\n",
    "                packet_info['tcp_flags']['ack'] = packet[TCP].flags.A\n",
    "                packet_info['tcp_flags']['urg'] = packet[TCP].flags.U\n",
    "            elif packet.haslayer(UDP):\n",
    "                packet_info['protocol'] = 'UDP'\n",
    "                packet_info['src_port'] = packet[UDP].sport\n",
    "                packet_info['dst_port'] = packet[UDP].dport\n",
    "            elif packet.haslayer(ICMP):\n",
    "                packet_info['protocol'] = 'ICMP'\n",
    "        \n",
    "        # Update protocol counts\n",
    "        traffic_data['protocol_distribution'][packet_info['protocol']] += 1\n",
    "        \n",
    "        # Add to packet buffer\n",
    "        traffic_data['packet_buffer'].append(packet_info)\n",
    "        traffic_data['stats']['total_packets'] += 1\n",
    "        \n",
    "        # Analyze packet for anomalies (every 10 packets)\n",
    "        if len(traffic_data['packet_buffer']) % 10 == 0:\n",
    "            analyze_packets()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing packet: {str(e)}\")\n",
    "\n",
    "def analyze_packets():\n",
    "    \"\"\"Analyze collected packets for anomalies\"\"\"\n",
    "    try:\n",
    "        if not traffic_data['packet_buffer']:\n",
    "            return\n",
    "            \n",
    "        # Get the most recent packet\n",
    "        recent_packet = traffic_data['packet_buffer'][-1]\n",
    "        \n",
    "        # Simulate anomaly detection (replace with actual model predictions)\n",
    "        if random.random() < 0.05:  # 5% chance of anomaly for demo\n",
    "            anomaly_types = ['Port Scan', 'DDoS', 'Malware', 'Brute Force', 'Data Exfiltration']\n",
    "            anomaly = {\n",
    "                'timestamp': recent_packet['timestamp'],\n",
    "                'anomaly_type': random.choice(anomaly_types),\n",
    "                'src_ip': f\"192.168.{random.randint(1,255)}.{random.randint(1,255)}\",  # Placeholder\n",
    "                'anomaly_score': round(random.uniform(0.7, 1.0), 2)\n",
    "            }\n",
    "            traffic_data['anomalies'].append(anomaly)\n",
    "            \n",
    "            # Generate alert for high score anomalies\n",
    "            if anomaly['anomaly_score'] > 0.9:\n",
    "                alert = {\n",
    "                    'timestamp': recent_packet['timestamp'],\n",
    "                    'severity': 'high',\n",
    "                    'message': f\"{anomaly['anomaly_type']} detected from {anomaly['src_ip']}\"\n",
    "                }\n",
    "                traffic_data['alerts'].append(alert)\n",
    "        \n",
    "        # Keep only recent data\n",
    "        traffic_data['anomalies'] = traffic_data['anomalies'][-20:]\n",
    "        traffic_data['alerts'] = traffic_data['alerts'][-20:]\n",
    "        traffic_data['packet_buffer'] = traffic_data['packet_buffer'][-100:]  # Keep last 100 packets\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing packets: {str(e)}\")\n",
    "\n",
    "def update_traffic_stats():\n",
    "    \"\"\"Update traffic statistics for visualization\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Update timestamps (last 30 minutes)\n",
    "            now = datetime.now()\n",
    "            traffic_data['timestamps'] = [(now - timedelta(minutes=i)).strftime('%H:%M') \n",
    "                                        for i in range(30, -1, -1)]\n",
    "            \n",
    "            # Generate packet counts based on actual traffic\n",
    "            # For demo, we'll use the total packets in the last 5 seconds\n",
    "            # In a real app, you'd want to track this more precisely\n",
    "            traffic_data['packet_counts'] = [random.randint(50, 200) for _ in range(31)]\n",
    "            \n",
    "            time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating traffic stats: {str(e)}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "def start_packet_capture():\n",
    "    \"\"\"Start packet capture in a separate thread\"\"\"\n",
    "    try:\n",
    "        print(\"Starting packet capture...\")\n",
    "        # Start sniffing packets (filter can be adjusted as needed)\n",
    "        sniff(prn=process_packet, store=0, filter=\"ip\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in packet capture: {str(e)}\")\n",
    "\n",
    "# Start background threads\n",
    "traffic_thread = threading.Thread(target=update_traffic_stats)\n",
    "traffic_thread.daemon = True\n",
    "traffic_thread.start()\n",
    "\n",
    "capture_thread = threading.Thread(target=start_packet_capture)\n",
    "capture_thread.daemon = True\n",
    "capture_thread.start()\n",
    "\n",
    "# Route definitions (remain the same as in your original code)\n",
    "@app.route('/')\n",
    "def dashboard():\n",
    "    \"\"\"Render the main dashboard\"\"\"\n",
    "    settings = {\n",
    "        'preferred_model': 'kmeans',\n",
    "        'system_status': 'active',\n",
    "        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    alert_counts = {\n",
    "        'high': sum(1 for alert in traffic_data['alerts'] if alert['severity'] == 'high'),\n",
    "        'medium': sum(1 for alert in traffic_data['alerts'] if alert['severity'] == 'medium'),\n",
    "        'low': sum(1 for alert in traffic_data['alerts'] if alert['severity'] == 'low')\n",
    "    }\n",
    "    \n",
    "    return render_template('index.html',\n",
    "                         total_packets=traffic_data['stats']['total_packets'],\n",
    "                         total_anomalies=len(traffic_data['anomalies']),\n",
    "                         alert_counts=alert_counts,\n",
    "                         settings=settings,\n",
    "                         recent_anomalies=traffic_data['anomalies'][-5:][::-1],\n",
    "                         recent_alerts=traffic_data['alerts'][-5:][::-1])\n",
    "\n",
    "@app.route('/traffic_monitor')\n",
    "def traffic_monitor():\n",
    "    \"\"\"Traffic monitoring page\"\"\"\n",
    "    return render_template('traffic.html',\n",
    "                         traffic_stats=traffic_data,\n",
    "                         active_page='traffic_monitor')\n",
    "\n",
    "@app.route('/anomalies')\n",
    "def anomalies():\n",
    "    \"\"\"Anomalies page\"\"\"\n",
    "    return render_template('anomalies.html',\n",
    "                         anomalies=traffic_data['anomalies'][::-1],  # Show newest first\n",
    "                         active_page='anomalies')\n",
    "\n",
    "@app.route('/alerts')\n",
    "def alerts():\n",
    "    \"\"\"Alerts page\"\"\"\n",
    "    return render_template('alerts.html',\n",
    "                         alerts=traffic_data['alerts'][::-1],  # Show newest first\n",
    "                         active_page='alerts')\n",
    "\n",
    "@app.route('/model_management')\n",
    "def model_management():\n",
    "    \"\"\"Model management page\"\"\"\n",
    "    model_info = {\n",
    "        'autoencoder': {\n",
    "            'status': 'active' if models['autoencoder'] else 'inactive',\n",
    "            'last_trained': '2023-11-15',\n",
    "            'performance': {'accuracy': 0.92, 'precision': 0.88, 'recall': 0.90}\n",
    "        },\n",
    "        'kmeans': {\n",
    "            'status': 'active' if models['kmeans'] else 'inactive',\n",
    "            'last_trained': '2023-11-15',\n",
    "            'performance': {'accuracy': 0.85, 'precision': 0.82, 'recall': 0.83}\n",
    "        },\n",
    "        'isolation_forest': {\n",
    "            'status': 'active' if models['isolation_forest'] else 'inactive',\n",
    "            'last_trained': '2023-11-15',\n",
    "            'performance': {'accuracy': 0.89, 'precision': 0.87, 'recall': 0.88}\n",
    "        }\n",
    "    }\n",
    "    return render_template('models.html',\n",
    "                         model_info=model_info,\n",
    "                         active_page='model_management')\n",
    "\n",
    "@app.route('/system_settings')\n",
    "def system_settings():\n",
    "    \"\"\"System settings page\"\"\"\n",
    "    settings = {\n",
    "        'interface': 'eth0',\n",
    "        'capture_mode': 'promiscuous',\n",
    "        'alert_threshold': 'high',\n",
    "        'data_retention': '30 days',\n",
    "        'email_alerts': 'enabled',\n",
    "        'email_address': 'admin@example.com'\n",
    "    }\n",
    "    return render_template('settings.html',\n",
    "                         settings=settings,\n",
    "                         active_page='system_settings')\n",
    "\n",
    "# API endpoints\n",
    "@app.route('/api/traffic/stats')\n",
    "def traffic_stats():\n",
    "    \"\"\"API endpoint for traffic statistics\"\"\"\n",
    "    return jsonify({\n",
    "        'traffic_over_time': {\n",
    "            'labels': traffic_data['timestamps'],\n",
    "            'values': traffic_data['packet_counts']\n",
    "        },\n",
    "        'protocol_distribution': traffic_data['protocol_distribution']\n",
    "    })\n",
    "\n",
    "@app.route('/api/anomalies/recent')\n",
    "def recent_anomalies():\n",
    "    \"\"\"API endpoint for recent anomalies\"\"\"\n",
    "    count = int(request.args.get('count', 5))\n",
    "    return jsonify(traffic_data['anomalies'][-count:][::-1])\n",
    "\n",
    "@app.route('/api/alerts/recent')\n",
    "def recent_alerts():\n",
    "    \"\"\"API endpoint for recent alerts\"\"\"\n",
    "    count = int(request.args.get('count', 5))\n",
    "    return jsonify(traffic_data['alerts'][-count:][::-1])\n",
    "\n",
    "@app.route('/api/system/status')\n",
    "def system_status():\n",
    "    \"\"\"API endpoint for system status\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'active',\n",
    "        'models_loaded': bool(models['autoencoder'] and models['kmeans'] and models['isolation_forest']),\n",
    "        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create static/css directory if it doesn't exist\n",
    "    if not os.path.exists('static/css'):\n",
    "        os.makedirs('static/css')\n",
    "    \n",
    "    # For production use, set debug=False\n",
    "    app.run(host='0.0.0.0', port=5000, debug=True, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
